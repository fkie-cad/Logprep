replicas: 1
serviceAccount: basic-secret

image:
  registry: ghcr.io
  repository: fkie-cad/logprep
  tag: py3.11-stable

resources:
  limits:
    memory: "2Gi"
    cpu: "1"
  requests:
    memory: "2Gi"
    cpu: "250m"

securityContext:
  capabilities:
    drop:
      - ALL
  runAsNonRoot: true
  runAsUser: 1000
  readOnlyRootFilesystem: true

# Optional secrets that will be mounted into the pod
# Listed secrets are handled specially by the logprep deployment.
# Additional secrets will be mounted as usual.
# secrets:
#   certificates:
#     name: ca-cert # Name of the secret containing the ca certificate (or chain) in one data block
#   credentials:
#     name: logprep-credentials # Name of the secret containing the logprep credentials file
#   imagePullSecret:
#     name: logprep-image-pull-secret # Name of the secret containing the image pull secret
secrets: {}

# Boolean to signal to use affinity to avoid deploying multiple instances of the
# pod on the same node
affinity: false

# inject extra labels to the pod metadata
pod_extra_labels: {}

credentials: {}

# If enabled, the exporter will be started on the specified port and
# the metrics service and a prometheus PodMonitor will be deployed.
# You have to ensure, that the prometheus operator is installed and
# the PodMonitor resource is available.
exporter:
  enabled: true
  port: 8000
  service_port: 8001
  scrape_interval: 30s

# Logprep logging configuration. For more information see: https://logprep.readthedocs.io/en/latest/user_manual/configuration/index.html#configuration-file-structure
logger:
  level: INFO

configurations:
  - name: logprep-config
    data:
      version: 1
      process_count: 2
      timeout: 0.1

      pipeline: []

      input:
        kafka:
          type: confluentkafka_input
          topic: consumer
          kafka_config:
            bootstrap.servers: 127.0.0.1:9092
            group.id: cgroup3
            enable.auto.commit: "true"
            auto.commit.interval.ms: "10000"
            enable.auto.offset.store: "false"
            queued.min.messages: "100000"
            queued.max.messages.kbytes: "65536"
            statistics.interval.ms: "60000"
          preprocessing:
            version_info_target_field: Logprep_version_info
            log_arrival_time_target_field: event.ingested
            hmac:
              target: <RAW_MSG>
              key: "thisisasecureandrandomkey"
              output_field: Full_event
      output:
        opensearch:
          type: opensearch_output
          hosts:
            - 127.0.0.1:9200
          default_index: processed
          error_index: errors
          message_backlog_size: 10000
          timeout: 10000
          flush_timeout: 60
          max_retries: 3
          parallel_bulk: false
          user: admin
          secret: admin
        kafka:
          type: confluentkafka_output
          default: false
          topic: producer
          error_topic: errors
          flush_timeout: 300
          kafka_config:
            bootstrap.servers: 127.0.0.1:9092
            statistics.interval.ms: "60000"
