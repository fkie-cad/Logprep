version: "3.9"

# The following command must be executed after each restart on linux or elasticsearch exits with an error
# sudo sysctl -w vm.max_map_count=262144

services:
  opensearch-node1:
    image: opensearchproject/opensearch:latest
    container_name: opensearch-node1
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node1 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which installs demo certificates and security configurations to OpenSearch
      - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data # Creates volume called opensearch-data1 and mounts it to the container
    ports:
      - 9200:9200 # REST API
      - 9600:9600 # Performance Analyzer
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network
  opensearch-node2:
    image: opensearchproject/opensearch:latest
    container_name: opensearch-node2
    environment:
      - cluster.name=opensearch-cluster # Name the cluster
      - node.name=opensearch-node2 # Name the node that will run in this container
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # Nodes to look for when discovering the cluster
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # Nodes eligibile to serve as cluster manager
      - bootstrap.memory_lock=true # Disable JVM heap memory swapping
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # Set min and max JVM heap sizes to at least 50% of system RAM
      - "DISABLE_INSTALL_DEMO_CONFIG=true" # Prevents execution of bundled demo script which installs demo certificates and security configurations to OpenSearch
      - "DISABLE_SECURITY_PLUGIN=true" # Disables Security plugin
    ulimits:
      memlock:
        soft: -1 # Set memlock to unlimited (no soft or hard limit)
        hard: -1
      nofile:
        soft: 65536 # Maximum number of open files for the opensearch user - set to at least 65536
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data # Creates volume called opensearch-data2 and mounts it to the container
    networks:
      - opensearch-net # All of the containers will join the same Docker bridge network
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:latest
    container_name: opensearch-dashboards
    ports:
      - 5601:5601 # Map host port 5601 to container port 5601
    expose:
      - "5601" # Expose port 5601 for web access to OpenSearch Dashboards
    environment:
      - 'OPENSEARCH_HOSTS=["http://opensearch-node1:9200","http://opensearch-node2:9200"]'
      - "DISABLE_SECURITY_DASHBOARDS_PLUGIN=true" # disables security dashboards plugin in OpenSearch Dashboards
    networks:
      - opensearch-net

  kafka:
    image: bitnami/kafka:3.4
    container_name: kafka
    hostname: kafka
    expose:
      - 9092
      - 9093
    network_mode: host
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@127.0.0.1:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: sh -c "((sleep 15 && echo 'kafka up' && kafka-topics.sh --create --if-not-exists --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 4 --topic consumer)&) && /opt/bitnami/scripts/kafka/run.sh"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --topic consumer --describe"
        ]

  kafka-exporter:
    image: bitnami/kafka-exporter
    container_name: kafkaexporter
    command: [ "--kafka.server=127.0.0.1:9092" ]
    network_mode: host
    expose:
      - 9308
    depends_on:
      kafka:
        condition: service_healthy

  logprep:
    build:
      context: ..
    image: logprep
    container_name: logprep
    profiles:
      - logprep
    expose:
      - 8000
    network_mode: host
    depends_on:
      - kafka
      - opensearch-node1
      - opensearch-node2

    volumes:
      - ../quickstart/:/home/logprep/quickstart/
    entrypoint:
      - logprep
      - /home/logprep/quickstart/exampledata/config/pipeline.yml

  grafana:
    image: bitnami/grafana:latest
    container_name: grafana
    expose:
      - 3000
    network_mode: host
    volumes:
      - ../quickstart/exampledata/config/grafana/datasources:/opt/bitnami/grafana/conf/provisioning/datasources
      - ../quickstart/exampledata/config/grafana/dashboards:/opt/bitnami/grafana/conf/provisioning/dashboards
  prometheus:
    image: bitnami/prometheus:latest
    container_name: prometheus
    network_mode: host
    expose:
      - 9090
    volumes:
      - ../quickstart/exampledata/config/prometheus/prometheus.yml:/opt/bitnami/prometheus/conf/prometheus.yml
  config:
    image: nginx:latest
    container_name: config
    profiles:
      - basic_auth
    network_mode: host
    expose:
      - 8081
    volumes:
      - ../quickstart/exampledata:/usr/share/nginx/html:ro
      - ../quickstart/exampledata/config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ../quickstart/exampledata/config/nginx/conf.d:/etc/nginx/conf.d:ro
  keycloak:
    image: bitnami/keycloak:latest
    container_name: keycloak
    network_mode: host
    expose:
      - 8080
    profiles:
      - oauth2
    environment:
      KEYCLOAK_ADMIN_USER: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
      KEYCLOAK_DATABASE_HOST: localhost
      KEYCLOAK_DATABASE_PORT: 5432
      KEYCLOAK_DATABASE_NAME: keycloak
      KEYCLOAK_DATABASE_USER: keycloak
      KEYCLOAK_DATABASE_PASSWORD: bitnami
      KEYCLOAK_HTTP_PORT: 8080
      KEYCLOAK_HTTPS_PORT: 8443
      KEYCLOAK_BIND_ADDRESS: 127.0.0.1
  keycloak_db:
    image: bitnami/postgresql:latest
    container_name: keycloak_db
    network_mode: host
    expose:
      - 5432
    profiles:
      - oauth2
    environment:
      POSTGRESQL_PASSWORD: bitnami
      POSTGRESQL_POSTGRES_PASSWORD: bitnami
      POSTGRESQL_DATABASE: keycloak
      POSTGRESQL_USERNAME: keycloak
    volumes:
      # use this folder to persist your postgresql data by dumping the database to it after changes
      # outside the container: chmod 777 quickstart/exampledata/config/postgresql
      # inside the container: pg_dump keycloak -U keycloak -W --file /docker-entrypoint-initdb.d/keycloak_db.sql
      - ../quickstart/exampledata/config/postgresql:/docker-entrypoint-initdb.d
volumes:
  opensearch-data1:
  opensearch-data2:

networks:
  opensearch-net:
